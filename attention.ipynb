{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oewn7nm0gSo0"
   },
   "source": [
    "# 1. Understanding Attention\n",
    "\n",
    "- Before running the jupyter notebook, don't forget to copy it into your drive **(`File` => `Save a copy in Drive`)**. *Failing to do this step may result in losing the progress of your code.*\n",
    "- For this notebook, please replace the placeholder answers directly after a `#TODO` comment with your answers.\n",
    "- Please only use constants. If your want to use one row or column of `key` or `value` as your answer, please write that out (i.e., `torch.tensor([...])`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0dr9R_7hGvHN"
   },
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T02:39:42.120353Z",
     "start_time": "2025-02-19T02:39:42.115876Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"hello\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5IgrbAcuGut3",
    "ExecuteTime": {
     "end_time": "2025-02-19T02:39:42.174310Z",
     "start_time": "2025-02-19T02:39:42.165874Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Z2oro9ZqG3HI",
    "ExecuteTime": {
     "end_time": "2025-02-19T02:39:42.242656Z",
     "start_time": "2025-02-19T02:39:42.226242Z"
    }
   },
   "source": [
    "torch.manual_seed(447)\n",
    "\n",
    "key = torch.randn(4, 3)\n",
    "key /= torch.norm(key, dim=1, keepdim=True)\n",
    "key.round_(decimals=2)\n",
    "\n",
    "value = torch.randn(4, 3)\n",
    "value /= torch.norm(value, dim=1, keepdim=True)\n",
    "value.round_(decimals=2)\n",
    "\n",
    "print(f\"key:\\n{key}\")\n",
    "print(f\"value:\\n{value}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key:\n",
      "tensor([[ 0.4700,  0.6500,  0.6000],\n",
      "        [ 0.6400,  0.5000, -0.5900],\n",
      "        [-0.0300, -0.4800, -0.8800],\n",
      "        [ 0.4300, -0.8300,  0.3500]])\n",
      "value:\n",
      "tensor([[-0.0700, -0.8800,  0.4700],\n",
      "        [ 0.3700, -0.9300, -0.0700],\n",
      "        [-0.2500, -0.7500,  0.6100],\n",
      "        [ 0.9400,  0.2000,  0.2800]])\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GwAXAX6XHu8A",
    "ExecuteTime": {
     "end_time": "2025-02-19T02:39:42.296404Z",
     "start_time": "2025-02-19T02:39:42.288594Z"
    }
   },
   "source": [
    "def attention(query, key, value):\n",
    "    \"\"\"\n",
    "    Note that we remove scaling for simplicity.\n",
    "    \"\"\"\n",
    "    return F.scaled_dot_product_attention(query, key, value, scale=1)\n",
    "\n",
    "\n",
    "def check_query(query, target, key, value):\n",
    "    \"\"\"\n",
    "    Helper function for you to check if your query is close to the required target matrix.\n",
    "    \"\"\"\n",
    "    a_out = attention(query, key, value)\n",
    "    return (target - a_out).abs().max()"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-J1y16Y7Gix4"
   },
   "source": [
    "## 1.2. Selection via Attention"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bVCedC4XgRf4",
    "ExecuteTime": {
     "end_time": "2025-02-19T02:39:42.358923Z",
     "start_time": "2025-02-19T02:39:42.349399Z"
    }
   },
   "source": [
    "# Define a query vector to ”select” the first value vector\n",
    "\n",
    "\n",
    "def get_query121():\n",
    "    return torch.tensor([[4.7, 6.5, 6.0]])\n",
    "\n",
    "\n",
    "print(get_query121())\n",
    "\n",
    "# compare output of attention with desired output\n",
    "diff = check_query(get_query121(), value[0], key=key, value=value)\n",
    "print(diff)\n",
    "\n",
    "assert diff < 0.05"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.7000, 6.5000, 6.0000]])\n",
      "tensor(0.0004)\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OiqQ78tfgRLc",
    "ExecuteTime": {
     "end_time": "2025-02-19T03:39:36.952841Z",
     "start_time": "2025-02-19T03:39:36.936690Z"
    }
   },
   "source": [
    "# Define a query matrix which results in an identity mapping – select all the value vectors\n",
    "\n",
    "\n",
    "def get_query122():\n",
    "    return 10 * torch.tensor([[ 0.4700,  0.6500,  0.6000],\n",
    "                        [ 0.6400,  0.5000, -0.5900],\n",
    "                        [-0.0300, -0.4800, -0.8800],\n",
    "                        [ 0.4300, -0.8300,  0.3500]])\n",
    "\n",
    "\n",
    "print(get_query122())\n",
    "\n",
    "# compare output of attention with desired output\n",
    "diff = check_query(get_query122(), value, key=key, value=value)\n",
    "print(diff)\n",
    "\n",
    "assert diff < 0.05"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.7000,  6.5000,  6.0000],\n",
      "        [ 6.4000,  5.0000, -5.9000],\n",
      "        [-0.3000, -4.8000, -8.8000],\n",
      "        [ 4.3000, -8.3000,  3.5000]])\n",
      "tensor(0.0007)\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Write-up part:\n",
    "\n",
    "A transformer’s attention mechanism can “copy” or “re-use” the most relevant tokens by giving them high attention weight. In language modeling, this is highly valuable because the model often needs to reproduce or refer to words or phrases from the recent context (e.g., entity names, rare tokens, or repeating phrases). Being able to “copy” directly helps maintain consistency and coherence in generated text, especially for longer contexts or structured repetitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BKyVfgcqImGr"
   },
   "source": [
    "## 1.3. Averaging via Attention"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zaE-R68BMT5e",
    "ExecuteTime": {
     "end_time": "2025-02-19T02:39:42.502832Z",
     "start_time": "2025-02-19T02:39:42.488015Z"
    }
   },
   "source": [
    "# define a query vector which averages all the value vectors\n",
    "\n",
    "\n",
    "def get_query131():\n",
    "    return torch.tensor([[0.0, 0.0, 0.0]])\n",
    "\n",
    "\n",
    "print(get_query131())\n",
    "\n",
    "# compare output of attention with desired output\n",
    "target = torch.reshape(value.mean(0, keepdims=True), (3,))  # reshape to a vector\n",
    "diff = check_query(get_query131(), target, key=key, value=value)\n",
    "print(diff)\n",
    "\n",
    "assert diff < 0.05"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.]])\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jQKXRVuEhgZZ",
    "ExecuteTime": {
     "end_time": "2025-02-19T02:39:42.624713Z",
     "start_time": "2025-02-19T02:39:42.610473Z"
    }
   },
   "source": [
    "# define a query vector which averages the first two value vectors\n",
    "\n",
    "\n",
    "def get_query132():\n",
    "    S = 100.0\n",
    "    k0 = torch.tensor([[0.47, 0.65, 0.60]])\n",
    "    k1 = torch.tensor([[0.64, 0.50, -0.59]])\n",
    "    q = S * ((k0 + k1) / 2)\n",
    "    return q\n",
    "\n",
    "print(get_query132())\n",
    "\n",
    "# compare output of attention with desired output\n",
    "target = torch.reshape(\n",
    "    value[(0, 1),].mean(0, keepdims=True), (3,)\n",
    ")  # reshape to a vector\n",
    "diff = check_query(get_query132(), target, key=key, value=value)\n",
    "print(diff)\n",
    "\n",
    "assert diff < 0.05"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[55.5000, 57.5000,  0.5000]])\n",
      "tensor(0.0289)\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Write-up part:\n",
    "\n",
    "In a language‐modeling context, the model often needs to blend or “smoothly combine” information from multiple tokens—e.g. when resolving a coreference that depends on multiple clues, or when synthesizing context from multiple parts of a sentence or paragraph. The ability to aggregate via attention means the model can learn to produce representations that are “mixes” of relevant tokens, rather than copying just a single one. This flexibility to combine rather than only copy is crucial to capturing nuanced context and producing coherent, contextually informed predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wcqbi9hbIqb6"
   },
   "source": [
    "## 1.4. Interactions within Attention"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5ax_OQnjKxwW",
    "ExecuteTime": {
     "end_time": "2025-02-19T03:40:16.937808Z",
     "start_time": "2025-02-19T03:40:16.924579Z"
    }
   },
   "source": [
    "# Define a replacement for only the third key vector k[2] such that the result of attention\n",
    "# with the same unchanged query q from (1.3.2) averages the first three value vectors.\n",
    "m_key = key.clone()\n",
    "\n",
    "\n",
    "def get_key141():\n",
    "    key = torch.tensor([[ 0.4700,  0.6500,  0.6000],\n",
    "                  [ 0.6400,  0.5000, -0.5900],\n",
    "                  [-0.0300, -0.4800, -0.8800],\n",
    "                  [ 0.4300, -0.8300,  0.3500]])\n",
    "    return (key[0] + key[1]) / 2\n",
    "\n",
    "m_key[2] = get_key141()\n",
    "\n",
    "# compare output of attention with desired output\n",
    "diff = check_query(get_query132(), value[(0, 1, 2),].mean(0, keepdims=True), key=m_key, value=value)\n",
    "print(diff)\n",
    "\n",
    "assert diff < 0.05"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0198)\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-LF7F1yRJLjK",
    "ExecuteTime": {
     "end_time": "2025-02-19T03:40:27.207165Z",
     "start_time": "2025-02-19T03:40:27.198429Z"
    }
   },
   "source": [
    "# Define a replacement for only the third key vector k[2] such that the result of attention\n",
    "# with the same unchanged query q from (1.3.2) returns the third value vector v[2].\n",
    "m_key = key.clone()\n",
    "\n",
    "\n",
    "def get_key142():\n",
    "    key = torch.tensor([[ 0.4700,  0.6500,  0.6000],\n",
    "                        [ 0.6400,  0.5000, -0.5900],\n",
    "                        [-0.0300, -0.4800, -0.8800],\n",
    "                        [ 0.4300, -0.8300,  0.3500]])\n",
    "    avg = (key[0] + key[1]) / 2\n",
    "    return avg / avg.norm()\n",
    "\n",
    "\n",
    "m_key[2] = get_key142()\n",
    "m_key[2] /= m_key[2].norm()\n",
    "\n",
    "# compare output of attention with desired output\n",
    "diff = check_query(get_query132(), value[2], key=m_key, value=value)\n",
    "print(f\"diff = {diff}\")\n",
    "\n",
    "assert diff < 0.05"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff = 1.1920928955078125e-07\n"
     ]
    }
   ],
   "execution_count": 50
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
